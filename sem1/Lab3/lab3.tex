\input{preambul}
\begin{document}
\captionsetup[figure]{name=\footnotesize{Figure},labelsep=period, font=footnotesize}
\renewcommand{\thetable}{\Roman{table}}
\captionsetup[table]{labelsep=newline, singlelinecheck = false, justification= centering}
\begin{equation}
r_t = \sigma (W_r × [h_{t-1}, x_t])
\end{equation}
\begin{equation}
z_t = \sigma (W_z × [h_{t-1}, x_t])
\end{equation}
\begin{equation}
\bar h_t = tanh(W_{\bar h} \times [r_t \times h_{t-1}, x_t])
\end{equation}
\begin{equation}
h_t = (1 - z_t) \times h_{t-1} + z_t \times \bar h_t
\end{equation} 
\begin{equation}
y_r = \sigma(W_\sigma \times h_t)
\end{equation}
\par
Where $\sigma$ represents sigmod function, $z_t$ is the update
gate of the unit, sigmod function converges the value
of the update gate to 0 or 1, i.e., whether the value of
the previous step is remembered or discarded. $r_t$ is the
reset gate, the smaller $r_t$, the more information about
the previous state needs to be ignored, W is te weight
value, $h_t$ and $\bar h_t$ are the output and temporary hidden
states in the module.
\par
The GRU model has a lower computational cost with
faster training, so the model is extensively used in various
fields of deep learning. The structure of a single GRU
module is shown in Fig. 2.

\setcounter{figure}{1}

\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180701.png}
\caption{Structure of a single GRU model}
\end{figure}

\par
The GRU neural network in this work had a total of 6
layers and 1700 learnable properties. Table III illustrated
the structure of the GRU neural network.

   \begin{table}[!h]
       \centering
        \caption{\small\textsc{The Structure Of Gru Neural Networks\\}}
       \tiny{
       \begin{tabular}{|c|c|c|}
       \hline
          \textbf{Name}  &  \textbf{Activations} &  \textbf{Learnable Properties}\\
           \hline
           Sequence Input & 88(C) × 1(B) × 1(T) & \\
           \hline
             &  &InputWeights 18 × 88 \\
            GRU & 6(C) × 1(B) & RecurrentWeights 18 × 6\\
             &  & Bias 18 × 1\\
           \hline
            ReLU  & 6(C) × 1(B) & \\
            \hline
            Fully   & 2(C) × 1(B)  & Weights 2 × 6 \\
            Connected  & 2(C) × 1(B)  & Bias 2 × 1 \\
           \hline
            Softmax  & 2(C) × 1(B)  &\\
           \hline
            Classification Output   & 2(C) × 1(B)  &\\
           \hline
       \end{tabular}}
   \end{table}

\textit{E. Public Voice Datasets Used}  
\begin{spacing}{1,25}
\end{spacing}

\par
This paper used public datasets [11] collected from
188 PD patients (107 men, 81 women) aged 33-87
at Istanbul University. The control group includes 64
healthy individuals (23 men, 41 women) aged 41-82.\\
Participants were asked to sustainably pronounce the
vowel /a/ while a microphone set at 44.1 KHz recorded
their voice three times.
\par
DementiaBank [12] is a resource that collects voice,
video, and text data from older adults and patients with
AD. It contains two groups of participants; the elderly
group includes 60 healthy older adults from New York
City who ranged in age from 60 to 91 years, while
the AD group includes 64 patients from Pittsburgh who
ranged in age from 60 to 95 years. Each participant was
asked to answer a series of questions. Data were collected
using a specialized recording device, with recorded voice
data at a sampling rate of 44.1 kHz.
\par
Visualization of voice can help to extract feature
information. The voice waveform and spectrum of AD
are shown in Fig. 3.

\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180815.png}
\caption{Alzheimer data voice waveforms and spectrograms.}
\end{figure}

\begin{spacing}{1.25}
\textit{F. Training and Testing Process}   
\end{spacing}

\par 
After noise removal and signal segmentation of all the
voice data in the dataset, we extracted 88 voice signal
features for each voice window signal, and then created
a neural network for training and learning. In this paper,
a 6-layer GRU model was adopted. It’s model structure
is shown in Fig. 4.

\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180821.png}
\caption{Structure of 6-layer GRU model}
\end{figure}

\par
To avoid overfitting, we added a Relu layer after the
GRU layer and output the probability of class labels by
defining a Softmax layer to vectorize the labels ontehot before calculating the correctness. To accelerate the
model convergence, the training took a batch gradient
descent approach for weight update, and each batch
contained 64 features. A flow chart of the overall model
structure of the experiment is shown in Fig. 5.

\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180828.png}
\caption{Flow chart of the overall model structure of the experiment}
\end{figure}


\begin{spacing}{1.25}
\textit{G. Deploying the Model to the Thingspeak Platform}    
\end{spacing}
Thingspeak is an open source IoT application platform
that allows users to conveniently collect, process and
analyze data from IoT devices. The platform provides
a way for developers and manufacturers to collect, store,
analyze and visualize data from the center of IoT devices
and use that data for real-time decision-making and
operations.
To upload the sensor data from the mobile phone to the
Thingspeak IoT platform and read the results of the data
analysis using an application developed by ourselves, we
followed the following steps:
\setlist[itemize]{itemsep=0pt, parsep=0pt, partopsep=0pt, topsep=2pt}
\begin{itemize}
    \renewcommand{\labelitemi}{1)}
        \item Registering a Thingspeak account and creating new
channel.
    \renewcommand{\labelitemi}{2)}
        \item   Getting our channel write/read API Key, which we
can find in our Thingspeak account.
    \renewcommand{\labelitemi}{3)}
        \item Adding network authority and sensor permission
in our application.
    \renewcommand{\labelitemi}{4)}
        \item Adding the Thingspeak API library, we can get
the source code of the library from the Thingspeak
website 
    \renewcommand{\labelitemi}{5)}
        \item   Implementing the code to upload data in our application, the code should use HTTP protocol to
upload our sensor data to our Thingspeak channel,
providing the channel write API Key to authenticate our identity
    \renewcommand{\labelitemi}{6)}
        \item   After uploaded data, we can analyze the data
using Thingspeak’s analytics tool. Once we have
uploaded the data, we could use Thingspeak’s
analytics tool to analyze the data. To get the result
of data analysis by using HTTP GET request.
    \renewcommand{\labelitemi}{7)}
        \item   Implementing the code to read the analysis results
in our application. We need to get data analysis
results using HTTP GET request and read API key
to parse the results into JSON format so that we
can process and display the data in our application.
\end{itemize}
In summary, to upload the sensor data from the phone
to the Thingspeak IoT platform and read the data analysis
results, we need to register an account and create a
new channel, get the channel write/read API Key, add
network permissions and sensor permissions, add the
Thingspeak API library, implement the code to upload
the data, use the platform’s analysis tool to analyze the
data, implement the code to read the analysis results, and
parse the results into JSON format to process as well as
display the data in the application.
\par
Deployment of the GRU model to the Thingspeak IoT
platform for data analysis Data analysis on Thingspeak
using the GRU model involves the following steps:
\begin{itemize}

\renewcommand{\labelitemi}{1)}
\item Creating a new channel on Thingspeak to store
the data to be analyzed. We can use Thingspeak’s
REST API or MQTT API to add the sensor data
to the channel.
\renewcommand{\labelitemi}{2)}
\item   Training a GRU model on our local computer and
exporting the model to a format that can be used
on.
    \renewcommand{\labelitemi}{3)}
        \item Uploading the exported KNN model to the Thingspeak platform. We can use Thingspeak’s REST
API or MQTT API to upload the model to the
channel.
    \renewcommand{\labelitemi}{4)}
        \item Once the model is uploaded successfully, we can
use Thingspeak’s MATLAB analysis toolbox or
matlab scripts to load the model and classify the
uploaded data. In MATLAB, we can read the
uploaded data using the thingSpeakRead function,
load the GRU model using the load function, and
classify the data using the predict function.
    \renewcommand{\labelitemi}{5)}
        \item  Displaying the classification results on the user
interface of Thingspeak or sending the results to
our cell phone as well as to an email for easy
viewing of the identification results.

 \begin{center}
        \textsc{IV. Experiments and Results}\\
    \end{center}
\end{itemize}

\textit{A. Experimental Setup}  
\begin{spacing}{1.25}
\end{spacing}
In this paper, the feature datasets were divided into
training datasets and test datasets in the ratio of 9:1.
The training datasets were trained and validated using
the 5-fold cross-validation method, which was repeated
five times. The test datasets were then used to test the
final results. And We evaluated the experiment using the
confusion matrix [13].
The Table II showed the GRU neural network model
hyperparameter setting table in this experiment.\begin{spacing}{1.25}
\textit{B. Experiment Results and Evaluation}
\end{spacing}
The Fig. 6 showed the process of training the GRU
model in 1000 epochs based on the Parkinson’s public
voice datasets.
As seen in the Fig. 6, the GRU neural network
model based on the Parkinson’s public voice dataset
can converge substantially in a short time. The model
uses stochastic gradient descent and variable learning rate
in solving the minimization loss function, so there was

\begin{table}[!h]
       \centering
       
       \caption{\small\textsc{The Structure Of Gru Neural Networks\\}}
       \small{
       \begin{tabular}{|c|c|c|}
       \hline
           \textbf{Number}  & \textbf{Parameter Name} & \textbf{Parameter Value}\\
           \hline
            1 & Mini Batch Size & 64 \\
           \hline
            2 & Max Epochs & 1000\\
           \hline
            3  & Initial Learn Rate &0.01 \\
            \hline
            4   & Learn Rate Drop Factor  & 0.1\\
            \hline
            5  & Learn Rate Drop Period  &700 \\
           \hline
            6  & Shuffle  &every-epoch\\
           \hline
            7   & Optimization  &adam\\
           \hline
       \end{tabular}}
   \end{table}

   \begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180836.png}
\caption{The process of training the GRU model based on Parkinson’s
datasets in 1000 epochs.}
\end{figure}
\par
   
some jitter in the convergence process of the model, but
the general trend of the model accuracy was improved,
the loss function of the model corresponded to a decreasing trend. The final training accuracy of the model
reached 100\%.


\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180843.png}
\caption{a - confusion matrix of training datasets; b - confusion matrix
of testing datasets; c - prediction results for the training datasets; d -
prediction results for the testing datasets.}
\end{figure}


As can be seen from Fig. 7, the accuracy of the model
on the test set was 86.66 \%, while the accuracy on the
training set was much better than the accuracy on the test
set, the model may have been overfitted. The overfitting
phenomenon may arise because of the small amount of
data in the public voice dataset of Parkinson’s, coupled
with the uneven distribution of samples in this public
dataset, so the model’s performance was degraded.


\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180843.png}
\caption{a - confusion matrix of training datasets; b - confusion matrix
of testing datasets; c - prediction results for the training datasets; d -
prediction results for the testing datasets.}
\end{figure}


\par
As can be seen in Fig. 8, the model converged after the
Alzheimer’s voice training dataset was fed into the model
and entered 2000 training cycles. The Fig. 9 showed a
comparison of the prediction results and the confusion
matrix of the training and testing datasets for AD.


\begin{figure}[!h]
\centering
\includegraphics{Снимок экрана 2023-11-14 180855.png}
\caption{a - confusion matrix of testing datasets; b - confusion matrix
of training datasets.}
\end{figure}

\par
Table III showed the experimental results of PD recognition and AD using GRU based on the test datasets.
\begin{center}
   \begin{table}[!h]
       \centering
        \footnotesize{
       \caption{\footnotesize\textsc{The Experimental Results Of PD Recognition And AD
Using GRU Based ON The Test Datasets\\}}
       \begin{tabular}{|c|c|c|c|c|}
       \hline
            \textbf{Public} &  \textbf{Average} & \textbf{Average} &\textbf{Average}&\textbf{Test}\\
            \textbf{Datasets} &  \textbf{Precision} & \textbf{Sensetivity} &\textbf{F1 score}&\textbf{Accuracy}\\
            \hline
            Parkinson’s & 84.95 \% &83.10 \%& 84.01 \% & 86.66 \%\\
            \hline
            Alzheimer's & 67.60 \% & 67.50\% & 67.55\% & 68.27 \%\\
            \hline
       \end{tabular} }
   \end{table}
\end{center}
\par
In summary, the accuracy of the GRU-based PD model
could reach 86.67 \% on the test dataset and 100 \%
on the training dataset. On the testing datasets, the
average precision was 84.95 \%, the average sensitivity
was 83.10 \%, and the average F1 score was 84.01 \%.
This experimental result showed that the recognition of
PD using GRU algorithm based on freezing of gait data
was effective.
\par
However, the test results of the model on Alzheimer’s
data were not satisfactory, which may be due to the fact
that Alzheimer’s data were more complex and harder to
find feature points compared to Parkinson’s data, after
which we will try new models or improve the model in a


\end{document}
