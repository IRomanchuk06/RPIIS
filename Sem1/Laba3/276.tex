\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[left=15mm, top=17mm, right=15mm, bottom=15mm, nohead, nofoot]{geometry}
\usepackage{enumitem}
\usepackage{float}
\usepackage{multicol}


\setlist[itemize]{itemsep=0pt, parsep=0pt, partopsep=0pt, topsep=1.4pt}
\setcounter{page}{276}


\begin{document}
\begin{multicols}{2}

\hspace{7mm} \textbf{\{}

$\Leftarrow$ 
\hspace{1.5mm} \textit{ subdividing*: }

\hspace{7mm} \textbf{\{} $\bullet$
\hspace{5mm} \textit{judgment question of choosing true}

\hspace{10mm} $\bullet$
\hspace{5mm} \textit{judgment questions of choosing false}

\hspace{7mm} \textbf{\}}



   \begin{center}
    V. PROBLEM SOLVER
\end{center}
\vspace{-0.3cm}
One of the most important components of every intelligent system is the problem solver, which provides the ability to solve a variety of problems. The problem solver of any ostis-system (more precisely, the sc-model of the ostis-system problem solver) is a hierarchical system of knowledge processing agents in semantic memory (scagents) that interact only by specifying the actions they perform in the specified memory [1], [4].

Therefore, a problem solver for automatic generation of test questions and automatic verification of user answers has been developed based on the proposed approach, and its hierarchy is shown below in SCn-code:
\vspace{0.4cm}

\textit{\textbf{Problem solver for the automatic generation of testquestions and automatic verification of user answers}}

\begin{description}[ labelwidth=0.75cm]

\vspace{-0.3cm}

\item[$\Leftarrow$] \textit{decomposition of an abstract sc-agent*:}

\{ $\bullet$ \hspace{14pt} \textit{Sc-agent for automatic generation of test
question}
\begin{description}[ labelwidth=1.2cm, itemsep=-1.5mm]
\vspace{-0.3cm}
\item[$\Leftarrow$] textit{decomposition of an abstract sc-agent*: }

\leftskip=0.62cm \textbf{\{} $\bullet$ 
\hspace{7mm} \textit{Sc-agent for quick generation of test questions and test papers}

\leftskip=1cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for generating single type of test questions}

\leftskip=1cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for generating a single test paper}

\leftskip=0.7cm \textbf{\}}

\end{description}
\begin{description}[ labelwidth=0.9cm]
\item[$\bullet$]
\noindent \leftskip=0.7cm \textit{Sc-agent for automatic verification of user answers}

\vspace{-0.2cm}
\leftskip=0.35cm
\item[$\Leftarrow$] \textit{decomposition of an abstract sc-agent*:}

\end{description}

\leftskip=1.4cm \textbf{\{} $\bullet$ 
\hspace{7mm} \textit{Sc-agent for automatic scoring oftest papers}

\leftskip=1.7cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for calculating similarity between answers to objective questions}

\leftskip=1.7cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for calculating the similarity between answers to definition explanation questions}

\leftskip=1.7cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for converting a logical formula into PNF}

\leftskip=1.7cm $\bullet$ 
\hspace{7mm} \textit{Sc-agent for calculating the similarity between the answers to proof questions and problem-solving task}

\leftskip=1.4cm \textbf{\}}
\end{description}

\leftskip=0.8cm\textbf{\}}

\leftskip=0cm
The function of the sc-agent for quick generation of test questions and test papers is to automate the entire process from test question generation to test paper generation by initiating the corresponding sc-agents (sc-agent for generating single type of test questions and sc-agent for generating a single test paper).

The function of the sc-agent for automatic scoring of test papers is to implement automatic verification of user answers to test questions and automatic scoring of test papers by initiating sc-agents for calculating the similarity between user answers and sc-agents for converting a logical formula into PNF.

\begin{center}
VI. EVALUATING THE EFFECTIVENESS OF THE
SUBSYSTEM
\end{center}
\vspace{-0.3cm}
The effectiveness of the developed subsystem will be
evaluated from the following aspects:

\begin{itemize}
    \item availability of the generated test questions;
    \item difficulty level of the generated test papers;
    \item closeness between automatic scoring and manual scoring of user answers to subjective questions.
\end{itemize}

In order to evaluate the availability of the automatically generated test questions, 200 automatically generated test questions were randomly sampled from the tutoring system for discrete mathematics and the proportion of test questions that could be used directly was counted (Table I).

\vspace{-0.6cm}
\begin{table}[H]
\caption{\label{tab:canonsummary}TABLE. RESULTS OF THE EVALUATION OF THE AVAILABILITY OF THE GENERATED TEST QUESTIONS}
\begin{center}
\vspace{-0.3cm}
\begin{tabular}{|p{1.8cm}|p{2cm}|p{2cm}|p{1.6cm}|}
\hline
Availability indicators & Test questions that can be used directly & Test questions that 
can be used after modification & Unavailable test questions \\
\hline
Number of test questions (total 200) & 188 & 12 & 0 \\
\hline
Proportion & 94\% & 6 & 0\\
\hline
\end{tabular}
\end{center}
\end{table}

\vspace{-0.8cm}
It can be seen from Table I that of the 200 automatically generated test questions sampled at random, 94\% were able to be used directly and 6\% were able to be used after modification.

The difficulty of the test paper is closely related to the user’s score. Therefore, 40 second-year students were randomly selected to evaluate the difficulty of the test paper for discrete mathematics, which was automatically generated using the subsystem. 10 multiple-choice questions, 10 fill in the blank questions, 10 judgment questions, 2 definition explanation questions and 2 proof questions are included in this test paper. The maximum score for each objective question is 2 points, the maximum score for each subjective question is 10 points, and the maximum score for the whole test paper is 100 points (Table II).

From the Table II, it can be seen that the students’ scores generally follow a normal distribution. Therefore, it can be concluded that the difficulty of the current type


\end{multicols} 
\end{document}